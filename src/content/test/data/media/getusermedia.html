<html>
<head>
  <script type="text/javascript" src="webrtc_test_utilities.js"></script>
  <script type="text/javascript">
  $ = function(id) {
    return document.getElementById(id);
  };

  var gLocalStream = null;

  setAllEventsOccuredHandler(function() {
    gLocalStream.stop();
    reportTestSuccess();
  });

  function getSources() {
    MediaStreamTrack.getSources(function(devices) {
      document.title = 'Sources Available';
      sendValueToTest(JSON.stringify(devices));
    });
  }

  // Creates a MediaStream and renders it locally. When the video is detected to
  // be rolling, the title is changed and the stream should be stopped.
  function getUserMediaAndStop(constraints) {
    console.log('Calling getUserMediaAndStop.');
    navigator.webkitGetUserMedia(
        constraints,
        function(stream) { displayAndDetectVideo(stream, stopVideoTrack); },
        failedCallback);
  }

  // Requests getusermedia and expects it to fail.
  function getUserMediaAndExpectFailure(constraints) {
    console.log('Calling getUserMediaAndExpectFailure.');
    navigator.webkitGetUserMedia(
        constraints,
        function(stream) { failTest('Unexpectedly succeeded getUserMedia.'); },
        function(error) { reportTestSuccess(); });
  }

  // Creates a MediaStream and renders it locally. When the video is detected to
  // be rolling we return ok-stream-running through the automation controller.
  function getUserMediaAndGetStreamUp(constraints, waitTimeInSeconds) {
    console.log('Calling getUserMediaAndGetStreamUp.');
    navigator.webkitGetUserMedia(
        constraints,
        function(stream) {
          displayAndDetectVideo(
            stream,
            function() {
              sendValueToTest('ok-stream-running');
            });
        },
        failedCallback);
  }

  // Gets a video stream up, analyses it and returns the aspect ratio to the
  // test through the automation controller.
  function getUserMediaAndAnalyseAndStop(constraints) {
    console.log('Calling getUserMediaAndAnalyseAndStop.');
    navigator.webkitGetUserMedia(
        constraints, displayDetectAndAnalyzeVideo, failedCallback);
  }

  // This test that a MediaStream can be cloned and that the clone can
  // be rendered.
  function getUserMediaAndClone() {
    console.log('Calling getUserMediaAndClone.');
    navigator.webkitGetUserMedia({video: true, audio: true},
        createAndRenderClone, failedCallback);
  }

  // Creates two MediaStream and renders them locally. When the video of both
  // streams are detected to be rolling, we stop the local stream. Since both
  // streams have the same source, both video streams should stop. If they do,
  // the test succeeds.
  function twoGetUserMediaAndStop(constraints) {
    console.log('Calling Two GetUserMedia');
    navigator.webkitGetUserMedia(
        constraints,
        function(stream) {
          displayAndDetectVideo(stream, requestSecondGetUserMedia);
        },
        failedCallback);
    var requestSecondGetUserMedia = function() {
      navigator.webkitGetUserMedia(
          constraints,
          function(stream) {
            displayIntoVideoElement(stream,
                stopStreamAndVerifyAllLocalViewsDontPlayVideo, 'local-view-2');
          },
          failedCallback);
    };

    var stopStreamAndVerifyAllLocalViewsDontPlayVideo = function() {
      gLocalStream.getVideoTracks()[0].stop();

      // Since local-view and local-view-2 are playing the video from the same
      // source, both of them should stop.
      waitForVideoToStop('local-view');
      waitForVideoToStop('local-view-2');
    };
  }

  function failedCallback(error) {
    failTest('GetUserMedia call failed with code ' + error.code);
  }

  function plugStreamIntoVideoElement(stream, videoElement) {
    gLocalStream = stream;
    var localStreamUrl = URL.createObjectURL(stream);
    $(videoElement).src = localStreamUrl;
  }

  function displayIntoVideoElement(stream, callback, videoElement) {
    plugStreamIntoVideoElement(stream, videoElement);
    detectVideoPlaying(videoElement, callback);
  }

  function displayAndDetectVideo(stream, callback) {
    displayIntoVideoElement(stream, callback, 'local-view');
  }

  function displayDetectAndAnalyzeVideo(stream) {
    plugStreamIntoVideoElement(stream, 'local-view');
    analyzeVideo();
  }

  function createAndRenderClone(stream) {
    gLocalStream = stream;
    // TODO(perkj):  --use-fake-device-for-media-stream do not currently
    // work with audio devices and not all bots has a microphone.
    new_stream = new webkitMediaStream();
    new_stream.addTrack(stream.getVideoTracks()[0]);
    assertEquals(new_stream.getVideoTracks().length, 1);
    if (stream.getAudioTracks().length > 0) {
      new_stream.addTrack(stream.getAudioTracks()[0]);
      assertEquals(new_stream.getAudioTracks().length, 1);
      new_stream.removeTrack(new_stream.getAudioTracks()[0]);
      assertEquals(new_stream.getAudioTracks().length, 0);
    }

    var newStreamUrl = URL.createObjectURL(new_stream);
    $('local-view').src = newStreamUrl;
    waitForVideo('local-view');
  }

  function stopVideoTrack() {
    gLocalStream.getVideoTracks()[0].stop();
    waitForVideoToStop('local-view');
  }

  function waitAndStopVideoTrack(waitTimeInSeconds) {
    setTimeout(stopVideoTrack, waitTimeInSeconds * 1000);
  }

  function analyzeVideo() {
    detectAspectRatio(function(aspectRatio) {
      sendValueToTest(aspectRatio);
    });
  }

  // This function tries to calculate the aspect ratio shown by the fake capture
  // device in the video tag. For this, we count the amount of light green
  // pixels along |aperture| pixels on the positive X and Y axis starting from
  // the center of the image. In this very center there should be a time-varying
  // pacman; the algorithm counts for a couple of iterations and keeps the
  // maximum amount of light green pixels on both directions. From this data
  // the aspect ratio is calculated relative to a 320x240 window, so 4:3 would
  // show as a 1. Furthermore, since an original non-4:3 might be letterboxed or
  // cropped, the actual X and Y pixel amounts are compared with the fake video
  // capture expected pacman radius (see further below).
  function detectAspectRatio(callback) {
    var width = VIDEO_TAG_WIDTH;
    var height = VIDEO_TAG_HEIGHT;
    var videoElement = $('local-view');
    var canvas = $('local-view-canvas');

    var maxLightGreenPixelsX = 0;
    var maxLightGreenPixelsY = 0;

    var aperture = Math.min(width, height) / 2;
    var iterations = 0;
    var maxIterations = 10;

    var detectorFunction = function() {
      var context = canvas.getContext('2d');
      context.drawImage(videoElement, 0, 0, width, height);

      // We are interested in a window starting from the center of the image
      // where we expect the circle from the fake video capture to be rolling.
      var pixels = context.getImageData(width / 2, height / 2,
                                        aperture, aperture);

      var lightGreenPixelsX = 0;
      var lightGreenPixelsY = 0;

      // Walk horizontally counting light green pixels.
      for (var x = 0; x < aperture; ++x) {
        if (pixels.data[4 * x + 1] != COLOR_BACKGROUND_GREEN)
          lightGreenPixelsX++;
      }
      // Walk vertically counting light green pixels.
      for (var y = 0; y < aperture; ++y) {
        if (pixels.data[4 * y * aperture + 1] != 135)
          lightGreenPixelsY++;
      }
      if (lightGreenPixelsX > maxLightGreenPixelsX &&
          lightGreenPixelsX < aperture)
        maxLightGreenPixelsX = lightGreenPixelsX;
      if (lightGreenPixelsY > maxLightGreenPixelsY &&
          lightGreenPixelsY < aperture)
        maxLightGreenPixelsY = lightGreenPixelsY;

      var detectedAspectRatioString = "";
      if (++iterations > maxIterations) {
        clearInterval(detectorFunction);
        observedAspectRatio = maxLightGreenPixelsY / maxLightGreenPixelsX;
        // At this point the observed aspect ratio is either 1, for undistorted
        // 4:3, or some other aspect ratio that is seen as distorted.
        if (Math.abs(observedAspectRatio - 1.333) < 0.1)
          detectedAspectRatioString = "16:9";
        else if (Math.abs(observedAspectRatio - 1.20) < 0.1)
          detectedAspectRatioString = "16:10";
        else if (Math.abs(observedAspectRatio - 1.0) < 0.1)
          detectedAspectRatioString = "4:3";
        else
          detectedAspectRatioString = "UNKNOWN aspect ratio";
        console.log(detectedAspectRatioString + " observed aspect ratio (" +
                    observedAspectRatio + ")");

        // The FakeVideoCapture calculates the circle radius as
        // std::min(capture_format_.width, capture_format_.height) / 4;
        // we do the same and see if both dimensions are scaled, meaning
        // we started from a cropped or stretched image.
        var nonDistortedRadius = Math.min(width, height) / 4;
        if ((maxLightGreenPixelsX != nonDistortedRadius) &&
            (maxLightGreenPixelsY != nonDistortedRadius)) {
          detectedAspectRatioString += " cropped";
        } else
          detectedAspectRatioString += " letterbox";

        console.log("Original image is: " + detectedAspectRatioString);
        callback(detectedAspectRatioString);
      }
    }

    setInterval(detectorFunction, 50);
  }
  </script>
</head>
<body>
  <table border="0">
    <tr>
      <td>Local Preview</td>
    </tr>
    <tr>
      <td><video width="320" height="240" id="local-view"
          autoplay="autoplay"></video></td>
      <td><canvas width="320" height="240" id="local-view-canvas"
          style="display:none"></canvas></td>
    </tr>
    <tr>
      <td>Local Preview 2</td>
    </tr>
    <tr>
      <td><video width="320" height="240" id="local-view-2"
          autoplay="autoplay"></video></td>
      <!-- Canvases are named after their corresponding video elements. -->
      <td><canvas width="320" height="240" id="local-view-2-canvas"
          style="display:none"></canvas></td>
    </tr>
  </table>
</body>
</html>
