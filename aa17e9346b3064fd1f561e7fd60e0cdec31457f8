{
  "comments": [
    {
      "key": {
        "uuid": "95f77ded_ce1c94eb",
        "filename": "components/sync/engine_impl/loopback_server/loopback_server.cc",
        "patchSetId": 2
      },
      "lineNbr": 332,
      "author": {
        "id": 1153420
      },
      "writtenOn": "2017-10-11T17:47:55Z",
      "side": 1,
      "message": "I want to call out this line right here, which I was conflicted about. If we return a nullptr from PersistentTombstoneEntity::CreateFromEntity, should we still call DeleteChildren()?\n\nCommits don\u0027t seem to be atomic. If we commit 3 items, and the 2nd has a type of UNSPECIFIED, we\u0027ll stop there. The first item will be saved, the 3rd will not, and we will return a failure to the client. So should we process as much of the 2nd item as possible, delete all the children or not?\n\nThe right answer doesn\u0027t seem obvious, I lean towards not deleting children.\n\nAlternatively, this isn\u0027t reading from the disk/network. This is coming straight from Chrome. Might be reasonable to DCHECK(entity) and keep going. While the logic within the persistent_x classes need to handle from Chrome and from storage, here we don\u0027t. Maybe DCHECK is still the right way to go. Which would imply that my if (!entity) down on line 354 should be a DCHECK instead. WDYT?",
      "revId": "aa17e9346b3064fd1f561e7fd60e0cdec31457f8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "66997e8d_c6b2c2d7",
        "filename": "components/sync/engine_impl/loopback_server/loopback_server.cc",
        "patchSetId": 2
      },
      "lineNbr": 332,
      "author": {
        "id": 1000640
      },
      "writtenOn": "2017-10-13T10:40:29Z",
      "side": 1,
      "message": "I think we should strive for as much consistency as we can. Help me understand something here if  we are returning a failure what is the client going to do. Just continue as if nothing happened and possibly skip to sink this item of that type or retry the whole operation. If it retries then maybe this code needs to be further extended to roll-back if not doing as much as we can skipping failures sounds like the best we can do. Certainly DCHECK-ing whatever is not expected is good as it will at least make us aware if our assumptions turn wrong now or in the future.",
      "parentUuid": "95f77ded_ce1c94eb",
      "revId": "aa17e9346b3064fd1f561e7fd60e0cdec31457f8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "5147be3e_a4ecd20d",
        "filename": "components/sync/engine_impl/loopback_server/loopback_server.cc",
        "patchSetId": 2
      },
      "lineNbr": 332,
      "author": {
        "id": 1153420
      },
      "writtenOn": "2017-10-13T18:24:13Z",
      "side": 1,
      "message": "I\u0027m a bit worried that we\u0027re setting our selves up for a scenario where the loopback server will silently swallow failures and we\u0027re going to have a lot less insight about what\u0027s going wrong for stable users. Do some LocalSync users have UMA enabled? Or is UMA in general always disabled for enterprise domains that turn on LocalSync? It\u0027d be nice to go through and add a reporting mechanism that tallies failures in like an UMA histogram, and this path is only engaged for real loopback, not fake_server. I\u0027m still a bit hazy how useful DCHECKs are [supposed to be] in detecting failure. My understanding is that they\u0027re predominantly to be used for code readability. But without the CHECK we would have been unaware of 771598 for longer, so clearly there is some usefulness in reporting, even if we\u0027re not _supposed_ to be relying on it.\n\nAs for, what does the client do. I don\u0027t really know, it\u0027s confusing. We have partial and global failures. As far as I can tell, the loopback/fake_server doesn\u0027t use partial failures. A global failure means the client should assume that nothing worked for the commit. Will it retry, well that depends on the type of global failure. And what do we do in this particular scenario of returning nullptr from this method - we DCHECK on crbug.com/774180. It\u0027ll be a non-zero amount of work for me to figure out what we do w/o the DCHECK, but I\u0027m needing to figure this out as I write unittests, I think.\n\nI don\u0027t think rollback is truly necessary for the loopback server. The real server has a problem that some data types are recorded in multiple local, like SESSIONS is written to zipit and Footprints. One of those can succeed and the other could have a transient failure. And even worse, the transient failure may actually fail on the way back from the datastore, in that the write was actually successful, but we\u0027re not guaranteed to know that (2 generals problem).\n\nNow, having an entity stored in model type storage, that needs to be committed, but somehow causes the server to return a retry-able error on every commit, sounds like a bad situation to get into. We should exponentially backoff, but that just breaks everything else, forever. I\u0027ve never seen this happen with the real server, and we should similarly avoid that scenario here. But I think I need to understand things a little better before I know how to ensure this.",
      "parentUuid": "66997e8d_c6b2c2d7",
      "revId": "aa17e9346b3064fd1f561e7fd60e0cdec31457f8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a9ed9cc0_7b062616",
        "filename": "components/sync/engine_impl/loopback_server/loopback_server.cc",
        "patchSetId": 2
      },
      "lineNbr": 332,
      "author": {
        "id": 1000640
      },
      "writtenOn": "2017-10-17T07:35:38Z",
      "side": 1,
      "message": "What do you think about us having a flag to be able to switch between \"strict\" and \"relaxed\" mode for the loopback server. In strict mode it will fail early and DCHECK on those issues in relaxed more it will do best effort and continue. This way we can turn strict mode on for testing through the FakeServer wrapper class and keep it off for release. Since strict mode is strictly doing the same as relaxed but with more checks it should help us catch bugs.\n\nEventually you are right that the more tests we produce on that the fewer undefined conditions we will have to worry about.",
      "parentUuid": "5147be3e_a4ecd20d",
      "revId": "aa17e9346b3064fd1f561e7fd60e0cdec31457f8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    }
  ]
}