{
  "comments": [
    {
      "key": {
        "uuid": "2d0c98f8_d9e5705d",
        "filename": "components/machine_intelligence/assist_ranker_service.h",
        "patchSetId": 8
      },
      "lineNbr": 28,
      "author": {
        "id": 1002376
      },
      "writtenOn": "2017-10-24T20:14:17Z",
      "side": 1,
      "message": "Who hangs on the the returned predictor?\n\nIs there a convention/policy in place ensuring that we only build a single predictor for a given model?",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "fd44f6fb_67e1cccf",
        "filename": "components/machine_intelligence/assist_ranker_service.h",
        "patchSetId": 8
      },
      "lineNbr": 28,
      "author": {
        "id": 1212246
      },
      "writtenOn": "2017-10-25T05:31:25Z",
      "side": 1,
      "message": "In the current state, the feature code (e.g. Contextual Search) owns the predictor. But you raise a good point. There is no logic in place to guarantee that there is a single predictor for a model. There would be a conflict if two predictors are created to point to the same cache. It would be okay, but wasteful, if two predictor point to the same url but have a different filename.\n\nWe could redesign this so that the predictors are owned by AssistRankerService and kept in a map keyed by filename.\n\nI was also thinking that Ranker could own configs for each models, so that the FetchPredictor would only need to receive a string that points to a config. This would ensure that model filenames and urls are consistent. However, that would mean that Ranker would need to own the Finch features that holds the url params. I think that this might be the right thing in the long run. \n\nI added a comment and a TODO for now. Let me know if you think I should refactor now.",
      "parentUuid": "2d0c98f8_d9e5705d",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f898312e_76dc97ce",
        "filename": "components/machine_intelligence/assist_ranker_service.h",
        "patchSetId": 8
      },
      "lineNbr": 28,
      "author": {
        "id": 1002376
      },
      "writtenOn": "2017-10-25T15:32:51Z",
      "side": 1,
      "message": "I think the TODO is fine, since the final solution is still TBD. Maybe file a bug and TODO(crbug/NNNNN) instead of TODO(hamelphi)?",
      "parentUuid": "fd44f6fb_67e1cccf",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "c108891c_c2ebb45b",
        "filename": "components/machine_intelligence/assist_ranker_service.h",
        "patchSetId": 8
      },
      "lineNbr": 28,
      "author": {
        "id": 1212246
      },
      "writtenOn": "2017-10-26T07:05:34Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "f898312e_76dc97ce",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "4b1468b5_99ff0f01",
        "filename": "components/machine_intelligence/assist_ranker_service.h",
        "patchSetId": 8
      },
      "lineNbr": 30,
      "author": {
        "id": 1002376
      },
      "writtenOn": "2017-10-24T20:14:17Z",
      "side": 1,
      "message": "take params by const ref unless this method is going to move the copies into some other destination.",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f71060e0_aba00274",
        "filename": "components/machine_intelligence/assist_ranker_service.h",
        "patchSetId": 8
      },
      "lineNbr": 30,
      "author": {
        "id": 1212246
      },
      "writtenOn": "2017-10-25T05:31:25Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "4b1468b5_99ff0f01",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "d79f67ea_2f33e0a8",
        "filename": "components/machine_intelligence/assist_ranker_service_impl.cc",
        "patchSetId": 8
      },
      "lineNbr": 37,
      "author": {
        "id": 1002376
      },
      "writtenOn": "2017-10-24T20:14:17Z",
      "side": 1,
      "message": "Move this contents of this func (other than the DCHECK and call to GetModelPath) to a factory func on BinaryClassifierPredictor, make LoadModel protected, and here just return BinaryClassifierPredictor::Create(...);\n\nSee comment for BasePredictor::LoadModel.",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "bfc13186_c6ac370b",
        "filename": "components/machine_intelligence/assist_ranker_service_impl.cc",
        "patchSetId": 8
      },
      "lineNbr": 37,
      "author": {
        "id": 1212246
      },
      "writtenOn": "2017-10-25T05:31:25Z",
      "side": 1,
      "message": "See response in other comment",
      "parentUuid": "d79f67ea_2f33e0a8",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "33d6c53f_87737539",
        "filename": "components/machine_intelligence/base_predictor.cc",
        "patchSetId": 8
      },
      "lineNbr": 17,
      "author": {
        "id": 1002376
      },
      "writtenOn": "2017-10-24T20:14:17Z",
      "side": 1,
      "message": "maybe the model_loader should be passed via the constructor so there\u0027s no way to misuse this entrypoint?\n\nthis would simplify to just calling NotifyOfRankerActivity()\n\nhmmm... the loader constructor needs the predictor to already exist to that it can know who to notify OnModelAvailable and moving this to the constructor would create a circular dependency.  :(\n\nmaybe make this private and make it\u0027s caller a friend?\n\nbetter yet, make this protected and add a factory function to the derived classes:\n\ni.e....\n\n  static unique_ptr\u003cBinaryPredictor\u003e BinaryPredictor::Create(....) {\n    auto predictor \u003d MakeUnique\u003cBinaryPredictor\u003e();\n    auto loader \u003d ...;  // Copied from service impl.\n    predictor-\u003eLoadModel(std::move(loader));  // accessible since we\u0027re in the subclass.\n    return predictor;\n  }",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "b0402bf5_060f4a61",
        "filename": "components/machine_intelligence/base_predictor.cc",
        "patchSetId": 8
      },
      "lineNbr": 17,
      "author": {
        "id": 1212246
      },
      "writtenOn": "2017-10-25T05:31:25Z",
      "side": 1,
      "message": "The reason I moved the instantiation of the RankerModelLoader out of the BasePredictor constructor and exposed LoadModel() is to be able to inject a fake model loader for testing.\n\nIt makes testing derived predictor classes easier if we can call DerivedPredictor-\u003eLoadModel(MockModelLoader). We can do this with Friends, but we will have to friend every derived class, which is probably ok and safer than having LoadModel public.\n\nOne downside of the static factory, is that you have to repeat that boilerplate code in each derived class. Not really a big deal. Another downside is that we have to pass the url_request_context down the predictor factory, which makes it a bit less elegant in my opinion. Also, with the current implementation, it should be relatively easy to template the Fetch method so that it will work for every Predictor class.\n\nSo, I prefer the \"friend\" solution. Let me know what you think.",
      "parentUuid": "33d6c53f_87737539",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "b9b6f5e4_c0967a55",
        "filename": "components/machine_intelligence/base_predictor.cc",
        "patchSetId": 8
      },
      "lineNbr": 17,
      "author": {
        "id": 1002376
      },
      "writtenOn": "2017-10-25T15:32:51Z",
      "side": 1,
      "message": "Re: Injection\n\nAnother alternative would be to use net::TestUrlFetcher (see test_url_fetcher_factory.h) to create a response for your model\u0027s URL. This would let you get unit-test coverage for the creation process, which is currently uncovered.\n\nRe: Downsides\n\nI don\u0027t follow the boilerplate argument. Won\u0027t you just be moving the creation code from living in AssistRankerServerceImpl::FetchBlah to living in Blah::Create?\n\nFetchBlah could, if it always has a fixed signature, be templatized by model type to call the static Create function.",
      "parentUuid": "b0402bf5_060f4a61",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "7a98c395_12e22ba5",
        "filename": "components/machine_intelligence/base_predictor.cc",
        "patchSetId": 8
      },
      "lineNbr": 17,
      "author": {
        "id": 1212246
      },
      "writtenOn": "2017-10-26T07:05:34Z",
      "side": 1,
      "message": "I went with the factory pattern you suggested, while keeping the test class as a friend to allow injection.\nRe:Injection\nI think it is good to have a way to decouple the model_loader logic from the predictor logic for unittests related to the RankerModelProto content. I agree that we also need to have an integration test for the creation process. However, to do this right I think it might require to create some test utils for the model_loader. I left this as a TODO for now.\nRe:Downsides\nMy point was that with the creation process in AssistRankerService, we would not need Predictor-specific factory code. We would have something like AssistRankerService::FetchPredictor\u003cBlah\u003e, which would not require any extra code in the derived predictors. In any case, I don\u0027t feel strongly, so I followed your recommendation. The templating is not necessary for now, and we can wait until we have several predictors before we do that. Templating a virtual function is not straightforward, and may actually make the code harder to read.",
      "parentUuid": "b9b6f5e4_c0967a55",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "94ddc681_cd49c1e2",
        "filename": "components/machine_intelligence/generic_logistic_regression_inference.h",
        "patchSetId": 8
      },
      "lineNbr": 18,
      "author": {
        "id": 1002376
      },
      "writtenOn": "2017-10-24T20:14:17Z",
      "side": 1,
      "message": "Are these sentences both related to the TODO? The 2nd looks like class documentation.",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "b6f1bdbd_c20429e5",
        "filename": "components/machine_intelligence/generic_logistic_regression_inference.h",
        "patchSetId": 8
      },
      "lineNbr": 18,
      "author": {
        "id": 1212246
      },
      "writtenOn": "2017-10-25T05:31:25Z",
      "side": 1,
      "message": "Right, clang format messed it up. Fixed.",
      "parentUuid": "94ddc681_cd49c1e2",
      "revId": "9c6bdd836ee785d90ac518e98736598e956a4e90",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}