{
  "comments": [
    {
      "key": {
        "uuid": "971b79ec_4617c60a",
        "filename": "content/browser/renderer_host/render_process_host_impl.cc",
        "patchSetId": 6
      },
      "lineNbr": 1011,
      "author": {
        "id": 1001216
      },
      "writtenOn": "2017-11-13T05:41:00Z",
      "side": 1,
      "message": "Looks good.\n\nSanity check: Do we not need something similar in CreateOrUseSpareRenderProcessHost / MaybeTakeSpareRenderProcessHost, because those only return unused RPHs, and thus shouldn\u0027t return false from MayReuseHost or IsSuitableHost?",
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "0f9d1046_8e584994",
        "filename": "content/browser/renderer_host/render_process_host_impl.cc",
        "patchSetId": 6
      },
      "lineNbr": 1011,
      "author": {
        "id": 1118209
      },
      "writtenOn": "2017-11-14T23:00:56Z",
      "side": 1,
      "message": "Yes, that\u0027s the rationale.  \n\nIn practice, new processes returned from those functions might in fact return false for IsSuitableHost() if checked at the end of those functions, e.g., for a WebUI process, because we set its bindings much later.",
      "parentUuid": "971b79ec_4617c60a",
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "644a49a9_086314de",
        "filename": "content/browser/renderer_host/render_process_host_impl.cc",
        "patchSetId": 6
      },
      "lineNbr": 1011,
      "author": {
        "id": 1001216
      },
      "writtenOn": "2017-11-14T23:37:49Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "0f9d1046_8e584994",
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "40bbb8a1_362a9a17",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 243,
      "author": {
        "id": 1001216
      },
      "writtenOn": "2017-11-13T05:41:00Z",
      "side": 1,
      "message": "I am wondering if there\u0027s a bug here as well, since this seems a bit unexpected.  If the extension is uninstalled, shouldn\u0027t its ServiceWorker immediately go away, taking the unmatched registration with it?",
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "3f659782_0839898b",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 243,
      "author": {
        "id": 1118209
      },
      "writtenOn": "2017-11-14T23:00:56Z",
      "side": 1,
      "message": "Yes, there might be a bug there as well.  I\u0027ve chatted with Devlin, and it seems existing SWs should be shut down and unregistered when their extension gets uninstalled.  It seems there might be a race here, where the SW is spinning up right as the extension is getting removed, and the SW is still allowed to start.  I\u0027ve filed https://crbug.com/785027 for extensions/SW folks to follow up on this.",
      "parentUuid": "40bbb8a1_362a9a17",
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "199f7fcc_41c4daef",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 243,
      "author": {
        "id": 1001216
      },
      "writtenOn": "2017-11-14T23:37:49Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "3f659782_0839898b",
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5a1d9d50_1c9113aa",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 259,
      "author": {
        "id": 1118209
      },
      "writtenOn": "2017-11-10T18:42:38Z",
      "side": 1,
      "message": "This is kind of ugly. :(  Basically, this is because RPHI::IsSuitableHost checks origin locks, and allowing reuse for matching locks, before checking the content client.  So the issue I described with nonexisting extensions in https://crbug.com/782349 won\u0027t occur with --site-per-process, as origin locks effectively override the process privilege level comparison.\n\nI still think having IsSuitableHost() checks in the Unmatched SW tracker makes sense to have in general, but perhaps we should also consider changing CCBCEP::SiteInstanceGotProcess to assign PRIV_EXTENSION for nonexistent extensions, which would allow process reuse in this case without --site-per-process as well.  Or is that undesirable in general?",
      "range": {
        "startLine": 255,
        "startChar": 0,
        "endLine": 259,
        "endChar": 13
      },
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6189fc35_0c13af2c",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 259,
      "author": {
        "id": 1001216
      },
      "writtenOn": "2017-11-13T05:41:00Z",
      "side": 1,
      "message": "\u003e This is kind of ugly. :(  Basically, this is because RPHI::IsSuitableHost checks origin locks, and allowing reuse for matching locks, before checking the content client.  So the issue I described with nonexisting extensions in https://crbug.com/782349 won\u0027t occur with --site-per-process, as origin locks effectively override the process privilege level comparison.\n\nI think that\u0027s worth fixing on its own.  IsSuitableHost should probably be giving the content client a chance to return false, without the early return true for origin lock.  Can we change that part to:\n\n    if (lock_state !\u003d ChildProcessSecurityPolicyImpl::CheckOriginLockResult::\n                             HAS_EQUAL_LOCK)\n      return false;\n\n\u003e \n\u003e I still think having IsSuitableHost() checks in the Unmatched SW tracker makes sense to have in general, but perhaps we should also consider changing CCBCEP::SiteInstanceGotProcess to assign PRIV_EXTENSION for nonexistent extensions, which would allow process reuse in this case without --site-per-process as well.  Or is that undesirable in general?\n\nGood question, independent of the fix above.  I\u0027m debating between that and your other suggestion on the bug of having GetPrivilegeRequiredByUrl return PRIV_NORMAL for nonexistent extensions.  I don\u0027t think an attacker can control any content in nonexistent extension URLs, though it\u0027s a little weird to let them create an extension process for an otherwise invalid extension URL.\n\nThat said, maybe treating it consistently as PRIV_EXTENSION would help us with CanCommitURL checks down the line, such that we could enforce that no chrome-extension:// URLs can ever commit in a PRIV_NORMAL process?  That might be the nicest outcome if we\u0027ll be able to do it.",
      "parentUuid": "5a1d9d50_1c9113aa",
      "range": {
        "startLine": 255,
        "startChar": 0,
        "endLine": 259,
        "endChar": 13
      },
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "bf9f42d4_7b9a5cbd",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 259,
      "author": {
        "id": 1130134
      },
      "writtenOn": "2017-11-13T17:00:59Z",
      "side": 1,
      "message": "\u003e \u003e This is kind of ugly. :(  Basically, this is because RPHI::IsSuitableHost checks origin locks, and allowing reuse for matching locks, before checking the content client.  So the issue I described with nonexisting extensions in https://crbug.com/782349 won\u0027t occur with --site-per-process, as origin locks effectively override the process privilege level comparison.\n\u003e \n\u003e I think that\u0027s worth fixing on its own.  IsSuitableHost should probably be giving the content client a chance to return false, without the early return true for origin lock.  Can we change that part to:\n\u003e \n\u003e     if (lock_state !\u003d ChildProcessSecurityPolicyImpl::CheckOriginLockResult::\n\u003e                              HAS_EQUAL_LOCK)\n\u003e       return false;\n\u003e \n\u003e \u003e \n\u003e \u003e I still think having IsSuitableHost() checks in the Unmatched SW tracker makes sense to have in general, but perhaps we should also consider changing CCBCEP::SiteInstanceGotProcess to assign PRIV_EXTENSION for nonexistent extensions, which would allow process reuse in this case without --site-per-process as well.  Or is that undesirable in general?\n\u003e \n\u003e Good question, independent of the fix above.  I\u0027m debating between that and your other suggestion on the bug of having GetPrivilegeRequiredByUrl return PRIV_NORMAL for nonexistent extensions.  I don\u0027t think an attacker can control any content in nonexistent extension URLs, though it\u0027s a little weird to let them create an extension process for an otherwise invalid extension URL.\n\u003e \n\u003e That said, maybe treating it consistently as PRIV_EXTENSION would help us with CanCommitURL checks down the line, such that we could enforce that no chrome-extension:// URLs can ever commit in a PRIV_NORMAL process?  That might be the nicest outcome if we\u0027ll be able to do it.\n\nSome drive-by thoughts:\n\n1. There are various ways that CanCommitURL can make sure that extension-level data stays in sync / agrees with site/process allocations. \n\n1.1. In the reverted r512959 we started consulting extensions::ProcessMap::Get(browser_context) to verify that process_map-\u003eContains(enabled_extension-\u003eid(), process_id) IFF the URL being committed belongs to an *enabled* extension.\n\n1.2. I guess we can also compare GetProcessPrivilege vs GetPrivilegeRequiredByUrl.  I see that GetPrivilegeRequiredByUrl is restricted to *enabled* extensions.\n\n2. Ultimately ChromeContentBrowserClientExtensionsPart::CanCommitURL helps catch issues in extensions-related process allocation decisions, but to reject invalid DidCommitProvisionalLoad IPC in general, we need mojofication of NavigationRequest as proposed by Camille.  I guess I am trying to say that tightening of CanCommitURL is like a DCHECK - it is not an end in itself / it might be okay to sacrifice it for other goals.\n\n\nIf we care about CanCommitURL tightening, then I think we should not commit a URL of an uninstalled/disabled extension (and/or purge renderers hosting such a URL when the extension gets uninstalled/disabled).  To commit such an URL (and keep tightened CanCommitURL checks), we would have to make sure that the process is treated as an extension process by extensions::ProcessMap::Get and GetProcessPrivilege - such treatment seems undesirable.",
      "parentUuid": "6189fc35_0c13af2c",
      "range": {
        "startLine": 255,
        "startChar": 0,
        "endLine": 259,
        "endChar": 13
      },
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "85d2f39e_6032665c",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 259,
      "author": {
        "id": 1118209
      },
      "writtenOn": "2017-11-14T23:00:56Z",
      "side": 1,
      "message": "\u003e \u003e \u003e This is kind of ugly. :(  Basically, this is because RPHI::IsSuitableHost checks origin locks, and allowing reuse for matching locks, before checking the content client.  So the issue I described with nonexisting extensions in https://crbug.com/782349 won\u0027t occur with --site-per-process, as origin locks effectively override the process privilege level comparison.\n\u003e \u003e \n\u003e \u003e I think that\u0027s worth fixing on its own.  IsSuitableHost should probably be giving the content client a chance to return false, without the early return true for origin lock.  Can we change that part to:\n\u003e \u003e \n\u003e \u003e     if (lock_state !\u003d ChildProcessSecurityPolicyImpl::CheckOriginLockResult::\n\u003e \u003e                              HAS_EQUAL_LOCK)\n\u003e \u003e       return false;\n\u003e \u003e \n\nAgreed, might as well fix this here.  I changed that return to what you suggested and removed the special-case treatment for --site-per-process.  Thanks!\n\n\n\u003e \u003e \u003e \n\u003e \u003e \u003e I still think having IsSuitableHost() checks in the Unmatched SW tracker makes sense to have in general, but perhaps we should also consider changing CCBCEP::SiteInstanceGotProcess to assign PRIV_EXTENSION for nonexistent extensions, which would allow process reuse in this case without --site-per-process as well.  Or is that undesirable in general?\n\u003e \u003e \n\u003e \u003e Good question, independent of the fix above.  I\u0027m debating between that and your other suggestion on the bug of having GetPrivilegeRequiredByUrl return PRIV_NORMAL for nonexistent extensions.  I don\u0027t think an attacker can control any content in nonexistent extension URLs, though it\u0027s a little weird to let them create an extension process for an otherwise invalid extension URL.\n\u003e \u003e \n\u003e \u003e That said, maybe treating it consistently as PRIV_EXTENSION would help us with CanCommitURL checks down the line, such that we could enforce that no chrome-extension:// URLs can ever commit in a PRIV_NORMAL process?  That might be the nicest outcome if we\u0027ll be able to do it.\n\u003e \n\u003e Some drive-by thoughts:\n\u003e \n\u003e 1. There are various ways that CanCommitURL can make sure that extension-level data stays in sync / agrees with site/process allocations. \n\u003e \n\u003e 1.1. In the reverted r512959 we started consulting extensions::ProcessMap::Get(browser_context) to verify that process_map-\u003eContains(enabled_extension-\u003eid(), process_id) IFF the URL being committed belongs to an *enabled* extension.\n\u003e \n\u003e 1.2. I guess we can also compare GetProcessPrivilege vs GetPrivilegeRequiredByUrl.  I see that GetPrivilegeRequiredByUrl is restricted to *enabled* extensions.\n\u003e \n\u003e 2. Ultimately ChromeContentBrowserClientExtensionsPart::CanCommitURL helps catch issues in extensions-related process allocation decisions, but to reject invalid DidCommitProvisionalLoad IPC in general, we need mojofication of NavigationRequest as proposed by Camille.  I guess I am trying to say that tightening of CanCommitURL is like a DCHECK - it is not an end in itself / it might be okay to sacrifice it for other goals.\n\u003e \n\u003e \n\u003e If we care about CanCommitURL tightening, then I think we should not commit a URL of an uninstalled/disabled extension (and/or purge renderers hosting such a URL when the extension gets uninstalled/disabled).  To commit such an URL (and keep tightened CanCommitURL checks), we would have to make sure that the process is treated as an extension process by extensions::ProcessMap::Get and GetProcessPrivilege - such treatment seems undesirable.\n\nCurrently, navigating to a URL for a nonexistent extension results in the ERR_BLOCKED_BY_CLIENT error page.  So I think once we change that path to commit the error page URL instead (in Lukasz\u0027s https://chromium-review.googlesource.com/c/chromium/src/+/714336), then this shouldn\u0027t interfere with CanCommitURL.  If we wanted to tighten CanCommitURL before then and use IsSuitableHost in it, then it might still be desirable to fix this before then.\n\nIn any case, I\u0027ve filed https://crbug.com/785034 to sort out this mismatch.",
      "parentUuid": "bf9f42d4_7b9a5cbd",
      "range": {
        "startLine": 255,
        "startChar": 0,
        "endLine": 259,
        "endChar": 13
      },
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "26c01caa_dc7bcc01",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 259,
      "author": {
        "id": 1001216
      },
      "writtenOn": "2017-11-14T23:37:49Z",
      "side": 1,
      "message": "\u003e \u003e \u003e \u003e This is kind of ugly. :(  Basically, this is because RPHI::IsSuitableHost checks origin locks, and allowing reuse for matching locks, before checking the content client.  So the issue I described with nonexisting extensions in https://crbug.com/782349 won\u0027t occur with --site-per-process, as origin locks effectively override the process privilege level comparison.\n\u003e \u003e \u003e \n\u003e \u003e \u003e I think that\u0027s worth fixing on its own.  IsSuitableHost should probably be giving the content client a chance to return false, without the early return true for origin lock.  Can we change that part to:\n\u003e \u003e \u003e \n\u003e \u003e \u003e     if (lock_state !\u003d ChildProcessSecurityPolicyImpl::CheckOriginLockResult::\n\u003e \u003e \u003e                              HAS_EQUAL_LOCK)\n\u003e \u003e \u003e       return false;\n\u003e \u003e \u003e \n\u003e \n\u003e Agreed, might as well fix this here.  I changed that return to what you suggested and removed the special-case treatment for --site-per-process.  Thanks!\n\nGreat.\n\n\u003e \n\u003e \n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e I still think having IsSuitableHost() checks in the Unmatched SW tracker makes sense to have in general, but perhaps we should also consider changing CCBCEP::SiteInstanceGotProcess to assign PRIV_EXTENSION for nonexistent extensions, which would allow process reuse in this case without --site-per-process as well.  Or is that undesirable in general?\n\u003e \u003e \u003e \n\u003e \u003e \u003e Good question, independent of the fix above.  I\u0027m debating between that and your other suggestion on the bug of having GetPrivilegeRequiredByUrl return PRIV_NORMAL for nonexistent extensions.  I don\u0027t think an attacker can control any content in nonexistent extension URLs, though it\u0027s a little weird to let them create an extension process for an otherwise invalid extension URL.\n\u003e \u003e \u003e \n\u003e \u003e \u003e That said, maybe treating it consistently as PRIV_EXTENSION would help us with CanCommitURL checks down the line, such that we could enforce that no chrome-extension:// URLs can ever commit in a PRIV_NORMAL process?  That might be the nicest outcome if we\u0027ll be able to do it.\n\u003e \u003e \n\u003e \u003e Some drive-by thoughts:\n\u003e \u003e \n\u003e \u003e 1. There are various ways that CanCommitURL can make sure that extension-level data stays in sync / agrees with site/process allocations. \n\u003e \u003e \n\u003e \u003e 1.1. In the reverted r512959 we started consulting extensions::ProcessMap::Get(browser_context) to verify that process_map-\u003eContains(enabled_extension-\u003eid(), process_id) IFF the URL being committed belongs to an *enabled* extension.\n\u003e \u003e \n\u003e \u003e 1.2. I guess we can also compare GetProcessPrivilege vs GetPrivilegeRequiredByUrl.  I see that GetPrivilegeRequiredByUrl is restricted to *enabled* extensions.\n\nActually, Alex is pointing out that it isn\u0027t restrict to enabled extensions.  (We return PRIV_EXTENSION even when |extension| is null.)  But we can fix that in https://crbug.com/785034, once we decide whether it\u0027s better to treat it as PRIV_NORMAL or PRIV_EXTENSION.\n\n\n\u003e \u003e \n\u003e \u003e 2. Ultimately ChromeContentBrowserClientExtensionsPart::CanCommitURL helps catch issues in extensions-related process allocation decisions, but to reject invalid DidCommitProvisionalLoad IPC in general, we need mojofication of NavigationRequest as proposed by Camille.  I guess I am trying to say that tightening of CanCommitURL is like a DCHECK - it is not an end in itself / it might be okay to sacrifice it for other goals.\n\nI don\u0027t understand this point about CanCommitURL being like a DCHECK.  I thought a CanCommitURL failure would make us kill the renderer with RFH_CAN_COMMIT_URL_BLOCKED, so we wouldn\u0027t care about the Mojo work for this.\n\n\u003e \u003e \n\u003e \u003e \n\u003e \u003e If we care about CanCommitURL tightening, then I think we should not commit a URL of an uninstalled/disabled extension (and/or purge renderers hosting such a URL when the extension gets uninstalled/disabled).  To commit such an URL (and keep tightened CanCommitURL checks), we would have to make sure that the process is treated as an extension process by extensions::ProcessMap::Get and GetProcessPrivilege - such treatment seems undesirable.\n\u003e \n\u003e Currently, navigating to a URL for a nonexistent extension results in the ERR_BLOCKED_BY_CLIENT error page.  So I think once we change that path to commit the error page URL instead (in Lukasz\u0027s https://chromium-review.googlesource.com/c/chromium/src/+/714336), then this shouldn\u0027t interfere with CanCommitURL.  If we wanted to tighten CanCommitURL before then and use IsSuitableHost in it, then it might still be desirable to fix this before then.\n\u003e \n\u003e In any case, I\u0027ve filed https://crbug.com/785034 to sort out this mismatch.\n\nThanks!",
      "parentUuid": "85d2f39e_6032665c",
      "range": {
        "startLine": 255,
        "startChar": 0,
        "endLine": 259,
        "endChar": 13
      },
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "01e24dd7_7dac7f20",
        "filename": "content/browser/renderer_host/render_process_host_unittest.cc",
        "patchSetId": 6
      },
      "lineNbr": 259,
      "author": {
        "id": 1130134
      },
      "writtenOn": "2017-11-15T18:21:13Z",
      "side": 1,
      "message": "\u003e \u003e 2. Ultimately ChromeContentBrowserClientExtensionsPart::CanCommitURL helps catch issues in extensions-related process allocation decisions, but to reject invalid DidCommitProvisionalLoad IPC in general, we need mojofication of NavigationRequest as proposed by Camille.  I guess I am trying to say that tightening of CanCommitURL is like a DCHECK - it is not an end in itself / it might be okay to sacrifice it for other goals.\n\u003e \n\u003e I don\u0027t understand this point about CanCommitURL being like a DCHECK.  I thought a CanCommitURL failure would make us kill the renderer with RFH_CAN_COMMIT_URL_BLOCKED, so we wouldn\u0027t care about the Mojo work for this.\n\nI was missing that even without Mojo work we can make CanCommitURL consult IsSuitableHost and get generic commit IPC validation this way (generic \u003d not just specific to extensions).  If we have a generic protection (either via IsSuitableHost or via Mojo work), then we don\u0027t really need tightening of CanCommitURL by consulting extensions::ProcessMap (like in the reverted https://crrev.com/c/683312) - such extra checks would be like a DCHECK - they would only make sure that the other CanCommitURL checks and process decisions are shadowed consistently by extensions::ProcessMap.",
      "parentUuid": "26c01caa_dc7bcc01",
      "range": {
        "startLine": 255,
        "startChar": 0,
        "endLine": 259,
        "endChar": 13
      },
      "revId": "57fcc2874a06f65b1d5ede99704b9638bb618ab7",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}