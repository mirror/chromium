{
  "comments": [
    {
      "key": {
        "uuid": "713b4f25_f1f19ac0",
        "filename": "media/audio/fuchsia/audio_manager_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 93,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "Do you want to avoid resampling when possible? I.e. can we construct a fuschia audio stream at any sample rate and it\u0027ll handle resampling? We do this on CrOS and Android for power saving reasons. If so you should check the input params and use that sample rate.\n\nDitto on buffer size. If fuschia doesn\u0027t care, prefer the input params one (if it\u0027s valid). See what AudioManagerWin does here. You may want to carry over other values (like effects) from the input params if they\u0027re valid too.\n\nThere\u0027s also a GetUserBufferSize() override that may be useful to plumb if you want.",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "635b1529_d83b4e62",
        "filename": "media/audio/fuchsia/audio_manager_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 93,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "713b4f25_f1f19ac0",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "92e2540c_d1e2b9d3",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 101,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "Just due to the nature of scheduling this may happen under load I suspect. To tie this explicitly to suspend resume you\u0027d need to list to base::PowerObserver callbacks. But see my comment below to if we even need this.",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "fd9ef3b5_1a867f82",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 101,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "Yes, this would happen whenever the task is executed with a delay higher than buffer_duration.",
      "parentUuid": "92e2540c_d1e2b9d3",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "254041d1_fa4bde3e",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 113,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "This can also be affected by internal buffering on the OS side, so you may need to call it for every callback (it\u0027s what we do on most other platforms).",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c083a9e0_088edd79",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 113,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "The value returned from this function isn\u0027t affected by how much data is buffered for that stream.",
      "parentUuid": "254041d1_fa4bde3e",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "24f40eb5_afbb1b4d",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 126,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "Is this even really needed after my suggestion below?",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "442adc35_c02c7702",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 126,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "yes, I think we do need it.",
      "parentUuid": "24f40eb5_afbb1b4d",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "b69667ba_0fed3971",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 128,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "Why add buffer duration here?",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "abe1f9ac_b306cec2",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 128,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "fuchsia_audio_output_stream_get_min_delay() returns how far ahead we need to call fuchsia_audio_output_stream_write() to guarantee that this data is delivered to the mixer on time for the specified presentation_time. Some time may pass between zx_time_get() call here and fuchsia_audio_output_stream_write(), so we need to add some extra time to guarantee that the stream can still render that data on time.",
      "parentUuid": "b69667ba_0fed3971",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c6a7765e_005d3029",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 128,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-30T02:04:39Z",
      "side": 1,
      "message": "Huh, that\u0027s not a delay as Chrome is expecting it then unless there\u0027s some additional restrictions. I.e. time required to guarantee a gapless playout is not necessarily equivalent to the current delay. Will this return 10ms if there is 10ms of buffer remaining? Or is this returning |buffer_remaining| + |buffer_processing_time|? Delay as Chrome expects it should only be |buffer_remaining|.\n\nPer the docs I think you should only have pts \u003d zx_time_get() + min_delay_ns here. Otherwise you\u0027re baking in buffer_duration of delay until playback starts, which can be 20-500ms+ (BT) on other platforms. Which would be unfortunate given the importance of playback startup speed. Before ::Start() is called we request a buffer from the renderer, so the first fill should already be ready. The first call uses 0 for delay and delay timestamp.",
      "parentUuid": "abe1f9ac_b306cec2",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "25be2deb_9c5dabb8",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 128,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-10-02T18:20:33Z",
      "side": 1,
      "message": "\u003e Huh, that\u0027s not a delay as Chrome is expecting it then unless there\u0027s some additional restrictions. I.e. time required to guarantee a gapless playout is not necessarily equivalent to the current delay. Will this return 10ms if there is 10ms of buffer remaining? Or is this returning |buffer_remaining| + |buffer_processing_time|? Delay as Chrome expects it should only be |buffer_remaining|.\n\u003e \n\u003e Per the docs I think you should only have pts \u003d zx_time_get() + min_delay_ns here.\n\nI did that initially, but I don\u0027t think that would be right. We need to account for the time it takes to call OnMoreData(). if we set pts \u003d zx_time_get() + min_delay_ns here, then we would be calling write with (pts - zx_time_get()) \u003c min_delay_ns, which means that we can\u0027t be sure that the mixer will get that data on time to be mixed for the specified PTS. We do need to add some extra delay to min_delay. \n\n\u003e Otherwise you\u0027re baking in buffer_duration of delay until playback starts, which can be 20-500ms+ (BT) on other platforms.\n\nWhy would buffer_duration be as high as 500 ms? I don\u0027t think it\u0027s related to the total playback delay for the target device. E.g. on windows we use GetDevicePeriod(), which returns \"interval between periodic processing passes by the audio engine\". On Fuchsia fuchsia_audio_parameters.buffer_size is effectively the same thing. It\u0027s not related to the total presentation delay for the target device. Normally presentation delay will be many times higher than the period.\n\nbuffer_duration is essentially the interval between consecutive OnMoreData() calls, so it\u0027s maximum amount of time we can allow for each OnMoreData() call. Potentially we could use some fixed value (e.g. 2ms) instead of period duration. That would make this code more sensitive to timer error than necessary.\n\nIt might be better to rename AudioParamters::buffer_size to AudioParamters::period_size, to reflect the actual usage of that field. WDYT?\n\n\u003e Which would be unfortunate given the importance of playback startup speed. Before ::Start() is called we request a buffer from the renderer, so the first fill should already be ready. The first call uses 0 for delay and delay timestamp.",
      "parentUuid": "c6a7765e_005d3029",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "71e14a66_92eae0fb",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 128,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-10-02T21:20:21Z",
      "side": 1,
      "message": "\u003e \u003e Per the docs I think you should only have pts \u003d zx_time_get() + min_delay_ns here.\n\u003e \n\u003e I did that initially, but I don\u0027t think that would be right. We need to account for the time it takes to call OnMoreData(). if we set pts \u003d zx_time_get() + min_delay_ns here, then we would be calling write with (pts - zx_time_get()) \u003c min_delay_ns, which means that we can\u0027t be sure that the mixer will get that data on time to be mixed for the specified PTS. We do need to add some extra delay to min_delay. \n\nHow about the first call uses (0, now) for delay information and you choose the pts based on zx_time_get() after OnMoreData completes? In any case, you definitely can\u0027t use buffer duration here unless you want a bad experience or are guaranteed that value is always small.\n\n\u003e \n\u003e \u003e Otherwise you\u0027re baking in buffer_duration of delay until playback starts, which can be 20-500ms+ (BT) on other platforms.\n\u003e \n\u003e Why would buffer_duration be as high as 500 ms? I don\u0027t think it\u0027s related to the total playback delay for the target device. E.g. on windows we use GetDevicePeriod(), which returns \"interval between periodic processing passes by the audio engine\". On Fuchsia fuchsia_audio_parameters.buffer_size is effectively the same thing. It\u0027s not related to the total presentation delay for the target device. Normally presentation delay will be many times higher than the period.\n\nI don\u0027t really understand your question here. It\u0027s arbitrary in size. When connected to bluetooth devices you may be required to field very large buffers. It\u0027s possible Fuschia will rebuffer this internally somehow, but you probably shouldn\u0027t count on it. Just assume that buffer_duration could be anything.\n\n\u003e \n\u003e buffer_duration is essentially the interval between consecutive OnMoreData() calls, so it\u0027s maximum amount of time we can allow for each OnMoreData() call. Potentially we could use some fixed value (e.g. 2ms) instead of period duration. That would make this code more sensitive to timer error than necessary.\n\nThis isn\u0027t quite true, buffer duration is the _maximum_ allowed duration between calls, but the underlying platform may want the data ahead of time; so you can only consider it as an upper limit.\n\n\u003e \n\u003e It might be better to rename AudioParamters::buffer_size to AudioParamters::period_size, to reflect the actual usage of that field. WDYT?\n\nI don\u0027t think that\u0027s a worthwhile change; it just makes things more complicated when they\u0027re already quite complicated. We need less things on AudioParameters, not more :)",
      "parentUuid": "25be2deb_9c5dabb8",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "554cf5b7_e19270e1",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 132,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "Ditto, why are you adding in buffer duration here?",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "efed2d54_bb897935",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 132,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "same reason as above",
      "parentUuid": "554cf5b7_e19270e1",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "27d0e248_eff428d4",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 136,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "I think instead of GetCurrentStreamTime() you just want base::TimeTicks::Now() here. It\u0027s meant to be the time at which delay is calculated. I.e., if data is provided now, you can expect it to be played at timestamp + delay.",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "2f4431fb_2cee55ae",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 136,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "If we use base::TimeTicks::Now() for delay_timestamp then presentation_delay_ would have to be adjusted by delta\u003d(GetCurrentStreamTime() - base::TimeTicks::Now()) to supply correct value for delay. In general that delta is expected to be always close to zero (because that\u0027s how timer_ is scheduled below).\n\nBTW, is there any reason we need to pass both |delay| and |delay_timestamp| to OnMoreData()? I think it should be possible to replace them with a single base::TimeTicks playout_time (which would be sum of delay and delay_timestamp) It also looks like delay_timestamp is not always used properly, see https://codesearch.chromium.org/chromium/src/content/renderer/media/track_audio_renderer.cc?sq\u003dpackage:chromium\u0026l\u003d58 . I\u0027ll send you a CL to remove that TODO.",
      "parentUuid": "27d0e248_eff428d4",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "0d431534_02a4e75f",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 136,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-30T02:04:39Z",
      "side": 1,
      "message": "Hmm, delay_timestamp is not coded properly actually and I\u0027m not sure where it\u0027s being used. The computed value is wrong on Windows and is unused by the \u003cvideo\u003e/\u003caudio\u003e path. I guess WebAudio uses it, but no one has noticed it\u0027s wrong on the dominant platform; the FromQPCValue() calculation is incorrect. So I guess it doesn\u0027t matter what you put here :)\n\n\u003caudio\u003e definitely uses |delay| though; it requires that it mean that audio provided ::Now() will be heard after |delay| elapses. I\u0027m not sure that\u0027s what |min_delay| is actually returning though per my above comment, so we may have a problem here.\n\nplayout_time was proposed at one point, but it didn\u0027t seem to work for the WebAudio folk. I don\u0027t recall the exact details here, but you can see the proposal and changes here https://codereview.chromium.org/2101303004/#msg68\n\nIn any case, what you have here doesn\u0027t represent playout time, it is not accounting for elapsed time. Hence I think you want to use Now() and StreamTime + BufferDuration - Now() as your delay. Since per your above statement Now() and stream time are on the same clock, delay_timestamp should just be Now() and delay the time remaining until buffer exhaustion. If delay goes negative you\u0027ll have to reset your stream time as you\u0027re doing above.\n\nMissed callbacks should technically be filling in the frames_skipped field, but I don\u0027t think anything aside from ChromeCast uses that.\n\nTypically the platform exposes a get_pts type functionality (See Android, Windows) for facilitating this calculation. It will automatically fix this for suspend/resume jumps.",
      "parentUuid": "2f4431fb_2cee55ae",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "18ec4987_37878489",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 136,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-10-02T18:20:33Z",
      "side": 1,
      "message": "Ok, since delay_timestamp is not used properly, I updated this code to pass now as delay_timestamp and adjusted delay accordingly. I don\u0027t think matters much since GetCurrentStreamTime() is expected to be always close to Now() and delay is just an approximation.",
      "parentUuid": "0d431534_02a4e75f",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "9637fde9_8c45ae21",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 138,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "Probably can delete and just have the DCHECK_EQ below.",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "9f85bd49_d0e7e5d3",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 138,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "Isn\u0027t OnMoreData() allowed to return 0?",
      "parentUuid": "9637fde9_8c45ae21",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6c97e11e_7757e193",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 138,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-30T02:04:39Z",
      "side": 1,
      "message": "I took a look and I don\u0027t think anything returns zero for it actually. If we\u0027re unable to retrieve a full buffer AudioSyncReader return a full buffer of zeros. Ditto for AUdioOutputResampler. So probably we should just remove this return value nowadays.",
      "parentUuid": "9f85bd49_d0e7e5d3",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d104f2ad_1961e488",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 138,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-10-02T18:20:33Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "6c97e11e_7757e193",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f8af4195_d502855e",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 148,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "DCHECK_EQ",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "20724212_6936a79b",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 148,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "f8af4195_d502855e",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ce6c1a99_5b6a4ae4",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 162,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "With the removal of start time, using an AudioTimestampHelper will be sufficient here.",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "fc024ce7_0185c659",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 162,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "I don\u0027t think we can remove start_time_, see my comment below.",
      "parentUuid": "ce6c1a99_5b6a4ae4",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4987bae0_17639225",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 166,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "Why not just Now() + BufferDuration? Or something like Now() + BufferDuration *.75 if you want to try to ensure this doesn\u0027t glitch.",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d6523414_861ce525",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.cc",
        "patchSetId": 6
      },
      "lineNbr": 166,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "Some amount time is spent  in this function. Now() + BufferDuration doesn\u0027t account for that time, and so PumpSamples() would be executed at a rate lower than the target.  With Now() + BufferDuration *.75 we would get PumpSamples() would be called at the rate that\u0027s 1.33 of the target, which means it would be pumping more data than necessary.",
      "parentUuid": "4987bae0_17639225",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4a8e2d53_c7512615",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.h",
        "patchSetId": 6
      },
      "lineNbr": 34,
      "author": {
        "id": 1001250
      },
      "writtenOn": "2017-09-29T23:27:31Z",
      "side": 1,
      "message": "Can this be private? The caller is actually AudioManager I thought?",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "58c4dae3_06df5fb1",
        "filename": "media/audio/fuchsia/audio_output_stream_fuchsia.h",
        "patchSetId": 6
      },
      "lineNbr": 34,
      "author": {
        "id": 1116023
      },
      "writtenOn": "2017-09-30T00:42:53Z",
      "side": 1,
      "message": "AudioManagerBase calls AudioOutputStream::~AudioOutputStream(), which is not private. I think it would be great to make the destructor private in AudioOutputStream and then make AudioManagerBase a friend of AudioOutputStream. That\u0027s if we have to keep Close(). IMO it would be best to remove Close() completely as I suggested in my other comment. WDYT?",
      "parentUuid": "4a8e2d53_c7512615",
      "revId": "ba297ba57c4916b81c4d71a381df4464b291fd82",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    }
  ]
}