{
  "comments": [
    {
      "key": {
        "uuid": "01d06cfa_842487a7",
        "filename": "third_party/WebKit/Source/core/html/parser/HTMLTokenizerFuzzer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 17,
      "author": {
        "id": 1149974
      },
      "writtenOn": "2017-10-05T14:45:56Z",
      "side": 1,
      "message": "Would it make sense to try different options?",
      "range": {
        "startLine": 17,
        "startChar": 20,
        "endLine": 17,
        "endChar": 27
      },
      "revId": "02633ef5f099b7ecb3e102719ea2794e02426d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "74b85a85_6bd2aa15",
        "filename": "third_party/WebKit/Source/core/html/parser/HTMLTokenizerFuzzer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 17,
      "author": {
        "id": 1139834
      },
      "writtenOn": "2017-10-05T16:12:34Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "01d06cfa_842487a7",
      "range": {
        "startLine": 17,
        "startChar": 20,
        "endLine": 17,
        "endChar": 27
      },
      "revId": "02633ef5f099b7ecb3e102719ea2794e02426d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "36c0781a_5ff6ef2c",
        "filename": "third_party/WebKit/Source/core/html/parser/HTMLTokenizerFuzzer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 22,
      "author": {
        "id": 1149974
      },
      "writtenOn": "2017-10-05T14:45:56Z",
      "side": 1,
      "message": "Could you add a comment why we consume data by portions on this size? Also, does chunk of 1 byte length make sense here? Maybe we need at least 3, e.g. \"\u003cp\u003e\"? Sorry if it\u0027s stupid question :)",
      "range": {
        "startLine": 22,
        "startChar": 61,
        "endLine": 22,
        "endChar": 66
      },
      "revId": "02633ef5f099b7ecb3e102719ea2794e02426d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "99dcfa66_e1c910c7",
        "filename": "third_party/WebKit/Source/core/html/parser/HTMLTokenizerFuzzer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 22,
      "author": {
        "id": 1139834
      },
      "writtenOn": "2017-10-05T16:12:34Z",
      "side": 1,
      "message": "Comment added. The tokenizer deals with byte streams as they come in on the wire so it has logic to process partial streams and this lets us exercise that.",
      "parentUuid": "36c0781a_5ff6ef2c",
      "range": {
        "startLine": 22,
        "startChar": 61,
        "endLine": 22,
        "endChar": 66
      },
      "revId": "02633ef5f099b7ecb3e102719ea2794e02426d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4291e600_02ff7049",
        "filename": "third_party/WebKit/Source/core/html/parser/HTMLTokenizerFuzzer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 22,
      "author": {
        "id": 1139834
      },
      "writtenOn": "2017-10-05T17:00:13Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "99dcfa66_e1c910c7",
      "range": {
        "startLine": 22,
        "startChar": 61,
        "endLine": 22,
        "endChar": 66
      },
      "revId": "02633ef5f099b7ecb3e102719ea2794e02426d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "fb944540_f937de40",
        "filename": "third_party/WebKit/Source/core/html/parser/HTMLTokenizerFuzzer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 28,
      "author": {
        "id": 1149974
      },
      "writtenOn": "2017-10-05T14:45:56Z",
      "side": 1,
      "message": "Why do we create all these chunks and segments? What\u0027s wrong if we simply treat all the |data| as input and start looking for tokens in it? I assume that once \"tokenizer-\u003eNextToken\" returns false, we cannot continue? Could you please add a comment :)",
      "range": {
        "startLine": 28,
        "startChar": 4,
        "endLine": 28,
        "endChar": 25
      },
      "revId": "02633ef5f099b7ecb3e102719ea2794e02426d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "47ede938_ac34fc9c",
        "filename": "third_party/WebKit/Source/core/html/parser/HTMLTokenizerFuzzer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 28,
      "author": {
        "id": 1139834
      },
      "writtenOn": "2017-10-05T16:12:34Z",
      "side": 1,
      "message": "Comment added.  The tokenizer handles streaming data over the wire (as well as full token strings) and has logic for resuming partial streams.  Splitting it into chunks exercises the resuming of partial streams.  A false return can mean it has a partial token and needs to resume it as more data comes in.",
      "parentUuid": "fb944540_f937de40",
      "range": {
        "startLine": 28,
        "startChar": 4,
        "endLine": 28,
        "endChar": 25
      },
      "revId": "02633ef5f099b7ecb3e102719ea2794e02426d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c438e147_9684cb0b",
        "filename": "third_party/WebKit/Source/core/html/parser/HTMLTokenizerFuzzer.cpp",
        "patchSetId": 1
      },
      "lineNbr": 28,
      "author": {
        "id": 1139834
      },
      "writtenOn": "2017-10-05T17:00:13Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "47ede938_ac34fc9c",
      "range": {
        "startLine": 28,
        "startChar": 4,
        "endLine": 28,
        "endChar": 25
      },
      "revId": "02633ef5f099b7ecb3e102719ea2794e02426d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}