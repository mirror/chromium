{
  "comments": [
    {
      "key": {
        "uuid": "f8a5888c_12dd6370",
        "filename": "media/gpu/windows/d3d11_h264_accelerator.cc",
        "patchSetId": 11
      },
      "lineNbr": 82,
      "author": {
        "id": 1001027
      },
      "writtenOn": "2017-12-13T09:07:23Z",
      "side": 1,
      "message": "Would a wait here (with a timeout) and retry before return from this method be possible instead? If I understand correctly, the Decoder would not have to be aware of this then possibly?\n\nIf so, decoder_ should be running in an own (or at least internal to this class) thread then. The threading model of this class is not entirely clear to me, but other VDAs run the Decoders on their own threads (mostly to offload GPU Main).",
      "revId": "3fc357793d72ba064922d7712fa7eadff67a0668",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "7978810e_e74736b8",
        "filename": "media/gpu/windows/d3d11_h264_accelerator.cc",
        "patchSetId": 11
      },
      "lineNbr": 82,
      "author": {
        "id": 1130490
      },
      "writtenOn": "2017-12-13T16:31:26Z",
      "side": 1,
      "message": "at the moment, this will be called on the gpu main thread.  the reason is that sharing d3d11 textures between a video decoder and a d3d11 context on another thread is tricky.  at least, i wasn\u0027t able to make it work reliably.  there may be hardware on which it simply doesn\u0027t work.\n\nif that latter set is small, then maybe we just introduce a texture copy for those cases and can then run the decoder on another thread.  i have no way of figuring that out right now, though.  i also don\u0027t know if texture copies are an option at all for protected content.\n\nwe have some latitude since the d3d11 decoder isn\u0027t close to being ready for production.  for the short term, i can remove kTryAgain, in favor of blocking the main thread.  i can then focus on the performance / correctness questions about a texture copy.  then, either re-introduce kTryAgain or move the decoder to another thread before shipping it, depending on the results.\n\nplease let me know which you\u0027d prefer.",
      "parentUuid": "f8a5888c_12dd6370",
      "revId": "3fc357793d72ba064922d7712fa7eadff67a0668",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "56da4a44_fc104406",
        "filename": "media/gpu/windows/d3d11_h264_accelerator.cc",
        "patchSetId": 11
      },
      "lineNbr": 82,
      "author": {
        "id": 1001027
      },
      "writtenOn": "2017-12-15T09:07:31Z",
      "side": 1,
      "message": "Could we perhaps run H264Decoder on its own thread, and when it calls this method on its thread, PostTask from here to the GPU main with a WaitableEvent, and wait on it here?\n\nThe task on the gpu main could then attempt to call DecoderBeginFrame, and if needed to retry, keep reposting itself using PostDelayedTask back to gpu main, and once successful, stop reposting, signal the WaitableEvent waking up this method and letting decoder thread resume, returning to H264Decoder?",
      "parentUuid": "7978810e_e74736b8",
      "revId": "3fc357793d72ba064922d7712fa7eadff67a0668",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "55d0bcb7_40ea7ac5",
        "filename": "media/gpu/windows/d3d11_h264_accelerator.cc",
        "patchSetId": 11
      },
      "lineNbr": 82,
      "author": {
        "id": 1130490
      },
      "writtenOn": "2017-12-19T19:20:49Z",
      "side": 1,
      "message": "every call into D3D11H264Accelerator would have to be proxied over to the gpu main thread, in that case.\n\nright now, the VideoDecoder itself that uses all of this proxies over to the gpu main thread from some other (mojo) thread.  if we can combine those, so that the VideoDecoder and H264Decoder run on the mojo thread, and just hop the accelerator over to gpu main, then that seems like an improvement to me.\n\notherwise, it\u0027s a very large amount of thread hopping.\n\ni\u0027ll see if it\u0027s possible to do that.",
      "parentUuid": "56da4a44_fc104406",
      "revId": "3fc357793d72ba064922d7712fa7eadff67a0668",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    }
  ]
}